{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from mongo import attraction_db\n",
    "from model.google import Google\n",
    "from model.Word import Word\n",
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.com/maps/search/%E6%99%AF%E9%BB%9E'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage():\n",
    "    page_content = driver.page_source\n",
    "    # 將 HTML 內容轉換成 BeautifulSoup 物件，html.parser 為使用的解析器\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    # 透過 select 使用 CSS 選擇器 選取我們要選的 html 內容\n",
    "    return soup.select('.Nv2PK.THOPZb.CpccDe')\n",
    "\n",
    "def scrollPage(times):   # 滾動頁面\n",
    "    counter = 0\n",
    "    while counter <= times:\n",
    "        pane = driver.find_element(\"xpath\",'//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[1]')\n",
    "        driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", pane)\n",
    "        counter += 1\n",
    "\n",
    "def getElement():  # 抓取目前的所有留言\n",
    "    spots_list = []\n",
    "    scrollPage(5)\n",
    "    elements = getPage()\n",
    "\n",
    "    for element in elements:\n",
    "        name = element.select('.qBF1Pd.fontHeadlineSmall')[0].text\n",
    "        url = element.select('.hfpxzc')[0].get('href')\n",
    "        dataset = {}\n",
    "        dataset['name'] = name\n",
    "        dataset['google_url'] = url\n",
    "\n",
    "        spots_list.append(dataset)\n",
    "    return spots_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastSpot = ''\n",
    "while 7 == 7:\n",
    "    print(lastSpot)\n",
    "    spots_list = getElement()\n",
    "    if (spots_list[len(spots_list)-1][\"name\"] == lastSpot ):\n",
    "        break\n",
    "    lastSpot = spots_list[len(spots_list)-1][\"name\"]\n",
    "    time.sleep(1)\n",
    "    getElement()\n",
    "\n",
    "csv_file = './data/spot_list/spots.csv'\n",
    "if os.path.exists(csv_file):\n",
    "    with open(csv_file, mode=\"r\", newline=\"\", encoding=\"utf-8-sig\") as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        existing_data = list(reader)\n",
    "else:\n",
    "    existing_data = []\n",
    "\n",
    "for spot in spots_list:\n",
    "    existing_data.append(spot)\n",
    "\n",
    "print(len(existing_data))\n",
    "\n",
    "\n",
    "with open(csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8-sig\") as file:\n",
    "    # 定義 CSV 欄位\n",
    "    fieldnames = [\"name\", \"google_url\"]\n",
    "    # 建立 CSV 寫入器\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(existing_data)\n",
    "\n",
    "    print(f\"已將資料寫入 CSV 檔案：{csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/spot_list/spotsList_clean.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = dataset.drop_duplicates(subset=\"name\", keep=\"first\")\n",
    "df_unique.to_csv('./data/spot_list/spotsList.csv', index=False, encoding=\"utf-8-sig\")\n",
    "df_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_names = attraction_db.attractionInfo.distinct(\"name\")\n",
    "df_filtered = df_unique[~df_unique[\"name\"].isin(existing_names)]\n",
    "df_filtered.to_csv('./data/spot_list/spotsList.csv', index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_names = attraction_db.attractionInfo.distinct(\"name\")\n",
    "df = pd.read_csv('./data/spot_list/random_spotsList.csv')\n",
    "df_filtered = df[~df[\"name\"].isin(existing_names)]\n",
    "df_filtered.to_csv('./data/spot_list/spotsList_clean.csv', index=False, encoding=\"utf-8-sig\")\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TEST\n",
    "# ============================================\n",
    "\n",
    "spotsList = pd.read_csv('./data/spot_list/spotsList_clean.csv') \n",
    "\n",
    "for index, row in spotsList[558:570].iterrows():\n",
    "    print(index,row['name'],row['google_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得 Google URL\n",
    "\n",
    "name_to_url = {}\n",
    "with open('./data/spot_list/spotsList_clean.csv', 'r', encoding='utf-8') as spots_file:\n",
    "    spots_reader = csv.reader(spots_file)\n",
    "    next(spots_reader)  # 跳过标题行\n",
    "    for row in spots_reader:\n",
    "        name = row[0]  # 假设名称在第一列\n",
    "        url = row[1]   # 假设URL在第二列\n",
    "        name_to_url[name] = url\n",
    "\n",
    "def get_url_for_name(name):\n",
    "    return name_to_url.get(name, \"URL not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 含有多少沒有抓\n",
    "\n",
    "existing_names = attraction_db.attractionInfo.distinct(\"name\")\n",
    "df = pd.read_csv('./data/spot_list/spotsList_clean.csv')\n",
    "df_filtered = df[~df[\"name\"].isin(existing_names)]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 個別處理\n",
    "# ============================================\n",
    "\n",
    "name = '講美鎮海社區海堤公園'\n",
    "url  = get_url_for_name(name)\n",
    "\n",
    "data = pd.read_csv('./data/tfidf_csv/{}.csv'.format(name))\n",
    "tag_value = data['words'].tolist()\n",
    "\n",
    "place_detail_data = Google().get_place_info(name,url,tag_value)\n",
    "place_detail_data = json.loads(place_detail_data)\n",
    "print(place_detail_data)\n",
    "\n",
    "existing_data = attraction_db.attractionInfo.find_one({\n",
    "    \"$or\": [\n",
    "        {\"place_id\": place_detail_data[\"place_id\"]},\n",
    "        {\"id\": place_detail_data[\"id\"]}\n",
    "    ]\n",
    "})\n",
    "print(existing_data)\n",
    "if existing_data is None:\n",
    "    attraction_db.attractionInfo.insert_one(place_detail_data)\n",
    "    print(f\"{place_detail_data['name']}：已新增\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查未成功插入資料庫的景點\n",
    "\n",
    "existing_names = set(doc['name'] for doc in attraction_db.attractionInfo.find({}, {\"name\": 1}))\n",
    "\n",
    "csv_folder_path = './data/tfidf_csv/' \n",
    "csv_files = os.listdir(csv_folder_path)\n",
    "new_csv_files = [csv_file.split('.')[0] for csv_file in csv_files if csv_file.split('.')[0] not in existing_names]\n",
    "print(len(new_csv_files))\n",
    "print(new_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增缺少的景點\n",
    "wrong = []\n",
    "# new_csv_files = ['三峽螢火蟲秘境']\n",
    "for spot in new_csv_files:\n",
    "    name = spot\n",
    "    url = get_url_for_name(name)\n",
    "    try:\n",
    "        try:\n",
    "            tfidf = pd.read_csv('./data/tfidf_csv/{}.csv'.format(name))\n",
    "            tag_value = tfidf['words'].tolist()\n",
    "        except:\n",
    "            tag_value = []\n",
    "        \n",
    "        place_detail_data = Google().get_place_info(name,url,tag_value)\n",
    "        place_detail_data = json.loads(place_detail_data)\n",
    "        existing_data = attraction_db.attractionInfo.find_one({\n",
    "            \"$or\": [\n",
    "                {\"place_id\": place_detail_data[\"place_id\"]},\n",
    "                {\"id\": place_detail_data[\"id\"]}\n",
    "            ]\n",
    "        })\n",
    "        if existing_data is None:\n",
    "            attraction_db.attractionInfo.insert_one(place_detail_data)\n",
    "            print(f\"{place_detail_data['name']}：已新增\")\n",
    "        else:\n",
    "            wrong.append({\n",
    "                \"name\":place_detail_data['name'],\n",
    "                \"existing_data\":existing_data['name']\n",
    "            })\n",
    "            print(f\"{place_detail_data['name']}：未新增\",existing_data['name'])\n",
    "    except Exception as e:\n",
    "        wrong.append({\n",
    "            \"name\":name,\n",
    "            \"existing_data\":e\n",
    "        })\n",
    "        print(f\"錯誤訊息：{e}\")\n",
    "        continue\n",
    "\n",
    "print(wrong)\n",
    "with open(\"./data/warn/check.json\", \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(wrong, f, indent=2, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除不必要的景點\n",
    "for spot in new_csv_files:\n",
    "    name = spot\n",
    "    csv_file_path = './data/tfidf_csv/{}.csv'.format(name)\n",
    "    if os.path.exists(csv_file_path):\n",
    "        os.remove(csv_file_path)\n",
    "        print(f\"{name}.csv 已删除\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機排序景點\n",
    "\n",
    "list = pd.read_csv('./data/spot_list/spotsList.csv')\n",
    "print(list)\n",
    "\n",
    "random.seed(42)\n",
    "random_spotsList = list.sample(frac=1,random_state=random.randint(1,10000))\n",
    "print(random_spotsList)\n",
    "\n",
    "random_spotsList.to_csv('./data/spot_list/random_spotsList.csv',encoding=\"utf-8-sig\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 個別處理 2\n",
    "# ============================================\n",
    "ws_driver = CkipWordSegmenter(model=\"bert-base\")\n",
    "pos_driver = CkipPosTagger(model=\"bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_path = './data/set/' \n",
    "existing_names = attraction_db.attractionInfo.distinct(\"name\")\n",
    "csv_files = os.listdir(csv_folder_path)\n",
    "tfidf_files = [csv_file.split('.')[0] for csv_file in csv_files if csv_file.split('.')[0] not in existing_names]\n",
    "tfidf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in tfidf_files:\n",
    "    name = spot\n",
    "    url = get_url_for_name(name)\n",
    "    try:\n",
    "        dataset = pd.read_excel('./data/set/{}.xlsx'.format(name))\n",
    "        tag = Word(ws_driver,pos_driver).save(dataset)\n",
    "        tag_value = tag['words'].tolist()\n",
    "        \n",
    "        place_detail_data = Google().get_place_info(name,url,tag_value)\n",
    "        place_detail_data = json.loads(place_detail_data)\n",
    "        existing_data = attraction_db.attractionInfo.find_one({\n",
    "            \"$or\": [\n",
    "                {\"place_id\": place_detail_data[\"place_id\"]},\n",
    "                {\"id\": place_detail_data[\"id\"]}\n",
    "            ]\n",
    "        })\n",
    "        if existing_data is None:\n",
    "            attraction_db.attractionInfo.insert_one(place_detail_data)\n",
    "            print(f\"{place_detail_data['name']}：已新增\")\n",
    "        else:\n",
    "            print(f\"{place_detail_data['name']}：未新增\")\n",
    "    except Exception as e:\n",
    "        print(f\"錯誤訊息：{e}\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
